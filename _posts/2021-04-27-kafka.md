---
title: "Kafka 소개"
layout: post
date: '2021-04-27 09:25:52'
author: jsh
tags: Kafka
cover: "/assets/cover.jpg"
categories: Kafka
---

- 목차
  * Kafka란
  * Kafka 이전 제품
  * Kafka 살펴보기  
    * 카프카 메시징 모델
    * 디스크로의 데이터 영속화
    * 이해하기 쉬운 API 제공

     
### Kafka란

Apache Kafka는 여러 대의 분산 서버에서 대량의 데이터를 처리하는 분산 메시징 시스템이다.   
메시지(데이터)를 받고, 받은 메시지를 다른 시스템이나 장치에 보내기 위해 사용된다.   
Kafka는 여러 시스템과 장치를 연결하는 중요한 역할을 한다.


![/assets/1.apache-kafka.png](/assets/1.apache-kafka.png)

Kafka는 대량의 데이터를 <b>높은처리량</b>과 <b>실시간</b>으로 취급하기 위한 제품으로 다음 4가지를 실현할 수 있다.
  + 확장성 : 여러 서버로 확장 구성할 수 있기 때문에 데이터 양에 따라 시스템 확장이 가능하다.
  + 영속성 : 수신한 데이터를 디스크에 유지할 수 있기 때문에 언제라도 데이터를 읽을 수 있다.
  + 유연성 : 연계할 수 있는 제품이 많기 때문에 제품이나 시스템을 연결하는 허브 역할을 한다.
  + 신뢰성 : 메시지 전달 보증을 하므로 데이터 분실을 걱정하지 않아도 된다.

 ### Kafka 이전 제품
<b>Message Queue</b>   
한 건의 레코드 단위로 실시간 처리를 할 때 가장 먼저 떠오르는 것이 Message Queue 이다.   
Message Queue 제품으로는 IBM의 WebSphere MQ와 JMS(Java Messaging System) 사양을 따르는 Apache ActiveMQ 그 외 RabbitMQ가 있다.   
![/assets/2.messageQueue.png](/assets/2.messageQueue.png)

Message Queue에서 제공하는 기능은 제품마다 차이는 있지만 대략 다음과 같이 정리 할 수 있다.   
+ 강력한 전달 보증이 오버 스펙
  + IBM WebSphere MQ는 메시지 단위로 Transaction을 지원하는 기능이 있다. 하나의 메시지가 정확히 한번만 전송 되는 것을 보증할 수 있다.   
  JMS에도 사양으로 규정되어 있으며, Application에서 <b>commit()</b>이나 <b>rollback()</b>이라고 기술하면 각 커밋/롤백을 할 수 있다.
    그러나 메시지는 분실하지 않은 채 송수신 보증에 너무 중시한 나머지 처리량이 나오지 않는다.

+ 스케일 아웃이 용이한 제품이 아니다.    
  + 대량의 메시지를 처리하는 데 1대의 서버로만 대응하는 것은 한계가 있다.    
    그러므로 처음부터 여러 대의 서버를 사용할 것을 전제할 필요가 있었다.   
  물론 메시지 큐의 제품에도 클러스터 구성을 취하는 것이 있었지만 실제로는 가용성을 위한 중복 구성에 주안점을 두고 있었다.   
    처리성능을 높이는 목적으로 필요 시 노드를 추가할 수 있는 스케일 아웃 기능을 전제로 한 제품이 아니다.

+ 메시지가 대량으로 쌓이는 것을 예상하지 않았다
  + 카프카 등장 이전의 메시지 큐에서는 메시지를 쌓아둘 수 있었는데, 
    큐에 쌓인 메시지는 즉시 이용되는 것으로 예상하고 있었지 장시간에 걸쳐 대량으로 축적하는 것은 예상하지 않았다.
    링크드인에서는 실시간 처리뿐만 아니라 메시지를 배치 처리로 이용하는 것도 가정하고 있었다.
    일정량의 데이터를 일정 기간마다 묶음으로 받아 데이터 웨어하우스에서 처리하기 위해서는 데이터의
    축적 시간은 훨씬 길어야 했지만 기존 메시지 큐로는 감당할 수 없었다.

<b>로그 수집 시스템</b>  
![/assets/3.logCollect.png](/assets/3.logCollect.png)
+ HDFS로 데이터 축적과 배치 처리만 고려했다.
+ 알기 쉬운 API가 없다.
+ 수신하는 쪽이 임의로 메시지를 수신하기 어렵다.

<b>ETL 도구</b>   
데이터 발생원에서 데이터를 추출하고 필요에 따라 변환해 데이터베이스와 데이터 웨어하우스에 로드하는 기능을 갖춘 도구   
ETL 도구 예: DataStage, Interstage, Consminexus, Infomatica PowerCenter, Talend
![/assets/4.ETL.png](/assets/4.ETL.png)

+ 데이터를 파일 단위로 다룬다.
  + 한 건의 레코드 단위로 실시간 처리를 할 수 없다. 
+ 수신하는 쪽이 임의로 메시지를 수신하기 어렵다.
  + ETL 도구는 데이터를 추출, 변환하여 다른 데이터 저장소에 전달하는 것을 중점으로 두다보니 
  임의의 타이밍에 데이터를 읽을 수 있는 중계 역할을 하고 있지는 않음.

![/assets/5.kafka_request.png](/assets/5.kafka_request.png)

### Kafka 살펴보기
#### 카프카 메시징 모델
카프카에서는 큐잉 모델에서 실현한 <b>여러 Consumer가 분산(distributed)처리로 메시지를 소비</b>하는 모델과
pub/sub 모델에서 실현한 <b>여러 서브스크라이버(subscriber)에 동일한 메시지를 전달</b>하고,
<b>토픽 기반으로 전달 내용을 변경</b>하는 모델로 되어 있다.   
이 모델을 실현하기 위해 '컨슈머 그룹(Consumer Group)' 이라는 개념을 도입하여 컨슈머를 확장 구성할 수 있도록 설계하고 있다.

![/assets/6.consumerDistributed.png](/assets/6.consumerDistributed.png)

#### 디스크로의 데이터 영속화
다음 두가지 요규에 부응하기 위해 카프카는 브로커에 보낸 메시지를 디스크에 영속화 하고 있다.
+ 임의의 타이밍에 데이터를 읽는다.
+ 메시지를 잃지 않는다.(단, 고장에 의한 최근 메시지 손실 회피 목적은 아님)

메시지 큐에서도 데이터 영속화를 실시하는 제품이 있지만 실시간 접속에만 중점을 두고 있는 경우가 많으며 
기본적으로 장기 보존을 가정하지 않는다.   
배치 처리의 경우에는 데이터를 일정 기간마다 모아야 할 필요가 있기 때문에 데이터를 메모리에서만 유지하는 것은 용량 면에서 불가능하다.   
따라서 카프카의 메시지 영속화는 디스크에서 이루어 진다.   
카프카는 <b>디스크에 영속화함에도 불구하고 높은 처리량을 제공</b>한다는 특징이 있다.

또한 속속 들어오는 데이터를 받아들이면서 한 묶음으로 장기 보존을 목적으로 영속화 할 수 있기 때문에 카프카를
<b>스토리지 시스템</b>으로 간주 할 수 있다.   
이러한 특징을 활용하는 예로는 처리 순서대로 로그를 계속 남기는 커밋로그를 축적하기 위한 스토리지 시스템 등을 들 수 있다.

#### 이해하기 쉬운 API 제공
다음 요구 사항과 관련하하여 카프카에서 데이터 출입을 쉽게 하는 API 대해 설명한다.
+ 다양한 제품과 시스템에서 쉽게 연동한다.

카프카는 프로듀서와 컨슈머를 쉽게 접속 할 수 있도록 'Connect API'를 제공한다.   
각각 이 API를 이용하여 각종 외부 시스템과 접속한다.   
또한 API를 기반으로 카프카에 접속하기 위한 프레임워크로 Kafka Connect도 제공한다.

![/assets/7.kafka_connector.png](/assets/7.kafka_connector.png)

